dp: 
	exponential -> polynomial
	dfs -> dp
	4 elements:
		state: what does dp[i][j] mean
		function: formula for dp[i][j]
		initialization
		answer: where

path finding: 
	dijkstra's: 
		O(V ** 2)
		O(E log V) if use heap to determine next vertex to visit, 
			but only appreciably faster on large, sparse graphs
		does not work with negative weight edges
		pseudocode:
			for all nodes i:
				dist[i] = infinity
				visited[i] = false	// not reachable
				parent[i] = null	// no path to vertex yet
			
			dist[source] = 0
			while nodesVisited < graphSize:
				i = unvisited vertex closest to source
				// to find such node i, keep all dist to source in an array(or node)
				assert distance[i] != infinity, "graph not connected"
				visited[i] = true
				
				for all neighbors j of i:
					if dist[i] + weight[i][j] < dist[j]:
						dist[j] = dist[i] + weight[i][j]
						parent[j] = i
	
	floyd-warshall: 
		O(V ** 3)
		finds length of shortest paths between all pairs of vertices
		works with negative weight edges(no negative cycles)
		requires adjacency matrix
		dist[i][j] = weight[i][j] or infinity if no edge connects i and j
		Ɐ pair (u, v), if ∃ w ∋ dist(u -> w -> v) < dist[u][v] then update dist[u][v]
		miraculously requires only 1 iteration if ordered properly
		pseudocode: 
			// dist[i][j] = best known dist(i -> j) so far
			for i = (1 -> n):
				for j = (1 -> n):
					dist[i][j] = weight[i][j]
					// inf if not connected
			
			for k = (1 -> n): 
				for i = (1 -> n): 
					for j = (1 -> n): 
						if dist[i][k] + dist[k][j] < dist[i][j]: 
							dist[i][j] = dist[i][k] + dist[k][j];
		optimizations: 
			due to the symmetric nature of adjacency matrices, only iterate through half of the matrix
			check if dist[i][k] is inf before proceeding to the j loop
			pseudocode: 
				for i = (1 -> n):
					for j = (1 -> n):
						dist[i][j] = weight[i][j](inf if not connected)
				
				for k = (1 -> n): 
					for i = (1 -> n - 1): 
						if dist[i][k] < inf: 
							for j = (i + 1 -> n): 
								if dist[i][k] + dist[k][j] < dist[i][j]: 
									dist[i][j] = dist[i][k] + dist[k][j];
		
	bfs:
		O(b ** (d + 1)) time & mem (b = avg out-deg, d = depth)
		uses queue
		for unweighted graphs
		if V large E small, much faster than dijkstra's

mst: 
	prim's: 
		O(N ** 2)
		changing any element requires complete recalculation
		does not work with extra constraints(e.g. avg(dist) has to be low)
		works with multiple edges between 2 nodes
		does not extend to directed graphs
		pseudocode: 
			// dist[j] = dist from tree to node j
			// src[j] = node of current mst closest to node j
			for all nodes i: 
				dist[i] = infinity
				inTree[i] = false
				src[i] = null
			
			// add node 1 to tree
			treeSize = 1
			treeCost  0
			inTree[1] = true
			for all neighbors j of node 1: 		// update distances
				dist[j] = weight[1][j]
				src[j] = 1
			
			while treeSize < grashSize: 
				i = node with minimum dist to tree
				assert dist[i] != infinity, "graph not connected"
				
				// add edge (src[i], i) to mst
				treeSize++
				treeCost = treeCost + dist[i]
				inTree[i] = true
				
				// update dist after node i added
				for all neighbors j of i: 
					if dist[j] > weight[i][j]: 
						dist[j] = weight[i][j]
						src[j] = i

pattern searching: 
	kmp algorithm: 
		preprocess pattern to construct auxiliary lps[] of same size as pattern
		lps[i] = longest proper prefix of pattern[0 : i] which is also a suffix of pattern[0 : i]
		e.g. "AAAA" -> [0, 1, 2, 3]; "AABAACAABAA" -> [0, 1, 0, 1, 2, 0, 1, 2, 3, 4, 5]
		using lps to decide next positions: 
			start comparison with pattern[j] with j = 0 at current window of text
			keep incrementing i and j for matching characters text[i] and pattern[j]
			when there is a mismatch: 
				if j is 0, increment i to shift to next window
				otherwise, 
				known(when j > 0): pattern[0 : j - 1] matches text[i - j + 1 : i - 1]
				also from the definition of lps: lps[j - 1] = count of characters of pattern[0 : j - 1] that are both proper prefix and suffix
				conslusion: no need to match the lps[j - 1] characters text[i - j : i - 1] since they match(change only j to lps[j - 1])
			(also when pattern found, reset j to lps[j - 1] by the same reasoning)
		pseudocode: 
			len = 0		// length of previous longest prefix suffix
			i = 1
			lps[0] = 0	// lps[0] is always 0
			
			while i < len(pattern): 
				if pattern[i] == pattern[len]: 
					len++
					lps[i] = len
					i++
				else: 
					if len != 0: 
						len = lps[len - 1]
						// no i increment
					else: 
						lps[i] = len
						i++
			
			i = j = 0
			while i < len(text): 
				if pattern[j] == text[j]: 
					j++
					i++
				if j == len(pattern): 
					// pattern found at index (i - j)
					j = lps[j - 1]
				else if i < len(text) && pattern[j] != text[i]: 
					if j != 0: 
						j = lps[j - 1]
					else: 
						i++

knapsack: 
	given a collection of objects with size and value and the total space available, 
		find the set of objects that maximizes the sum of the value of the set with 
		size constrainted by the limit, the total number or size of any particular item
		used in the set cannot exceed its availability
	fractional knapsack: 
		allowed to place fractional objects in the knapsack
		O(N log N) since must first sort by value to size ratio(O(N ** 2) without sorting)
		rare to have both size and availability
			(do trivial transmation to have all objects of size 1, have availability = original size * availability, 
			and divide the value by original size)
		use greedy algorithm: 
			find the object with highest value to size ratio
			if total capacity remaining >= availability of object, put all in knapsack and iterate
			if total capacity remaining < availability of object, use as much as possible and terminate
	integer knapsack: 
		solvable using dp if knapsack small enough: 
			O(KN), K = size of knapsack, N = sum of availability of objects
			dp[i] = max value that a knapsack of size i can have
			update dp for an object of isze S by traversing in reverse order and seeing if 
				placing the objext into the knapsack of size K yields a better set than the 
				current best knapsack of size K + S
		if knapsack too large to allocate array, use recursive descent since NP-complete
		if all sizes are same, solve greedily, picking the objects in decreasing value order until knapsack full
		if values are all 1, solve greedily, picking the objects in increasing size order until knapsack full
	multiple knapsack: 
		more than 1 knapsack is to be filled(multiple integer knapsacks)
		state space is too large for dp, use recursive descent
		if values are all 1 && max # of objects that can be placed in all knapsacks is n, 
			then there is a solution which uses n smallest objects